\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}

<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library("MASS")
@


%% -- Article metainformation (author, title, ...) -----------------------------

\author{Cord Huchzermeyer~\orcidlink{0000-0002-0408-8981}\\Department of Ophthalmology, University Hospital Erlangen
   \And Iván Marín-Franch\\Computational Optometry}
\Plainauthor{Cord Huchzermeyer, Iván Marín-Franch}

\title{visualFields 1.0.7: Tools for Analyzing the Field of Vision in \proglang{R}}
\Plaintitle{visualFields 1.0.7: Tools for Analyzing the Field of Vision in R}
\Shorttitle{visualFields 1.0.7 in \proglang{R}}

\Abstract{
  The \pkg{visualFields} package is part of the Open Perimetry Initiative (OPI), 
  a standard for interfacing with visual field testing machines. This article 
  introduces the package, which provides tools for analyzing the field of vision, 
  including visualization, statistical analysis, and clinical interpretation of 
  visual-field loss and its change over time.
}

\Keywords{visualFields, Open Perimetry Initiative, visual field analysis, \proglang{R}}
\Plainkeywords{visualFields, Open Perimetry Initiative, visual field analysis, R}

\Address{
  Cord Huchzermeyer\\
  Department of Ophthalmology, University Hospital Erlangen \\
  E-mail: \email{c.huchzermeyer@posteo.de}\\
  \\
  Iván Marín-Franch\\
  Computational Optometry\\
  E-mail: \email{ivan@example.com}\\
  URL: \url{https://www.computationaloptometry.com/}
}

\begin{document}
%%\SweaveOpts{concordance=TRUE}


%% -- Introduction -------------------------------------------------------------

\section[Introduction: Visual Fields in R]{Introduction: Visual Fields in \proglang{R}} \label{sec:intro}



The Open Perimetry Initiative (OPI) \citep{IMF:Tur2012, IMF:Marin2022a} is an open standard for interfacing with visual field testing devices (perimeters). It defines a set of core functions that enable the construction of a wide range of visual field tests. As of October 2017, OPI is fully implemented on the Octopus 900 and partially supported on the Heidelberg Edge Perimeter, Kowa AP 7000, CrewT IMO, and Centervue Compass.

The \pkg{visualFields} package, developed as part of the OPI ecosystem, provides a suite of tools for the statistical analysis and visualization of visual field data. It offers a flexible framework to support the development and application of innovative methods for analyzing visual field loss and its progression over time, with applications in both research and clinical settings.
\subsection{What is the visual field?}

The visual field refers to the entire area that can be seen at a given moment, encompassing both central and peripheral vision. It is typically measured in degrees of visual angle, with the fixation point defined as the origin at $x = 0^\circ$ and $y = 0^\circ$. Locations temporal and superior to fixation are represented by positive angles, while those nasal and inferior are denoted by negative angles.

In healthy vision, most visual functions, particularly light sensitivity, decline with increasing eccentricity—i.e., distance from the center of fixation. This decline in differential light sensitivity forms a three-dimensional structure known as the hill of vision, also referred to as Traquair’s island of vision \citep{IMF:Traquair1938}. Figure~\ref{hill} below shows a classic rendering of the hill of vision by Aulhorn and Harms \citep{IMF:Aul1967}.

\begin{figure}[t!]
\centering
\includegraphics[width=0.75\textwidth]{AulhornHillOfVision.png}
\caption{\label{fig:hill} Hill of vision as rendered by Aulhorn \& Harms.}
\end{figure}

\subsection{What is perimetry?}

\emph{Perimetry} (visual field testing) uses psychophysical methods to quantify the visual field by measuring a patient's sensitivity to light differences at various locations within the field. Psychophysical tests allow for the scientific measurement of the relationship between physical stimulus strength and subjective perception. This is achieved by systematically varying the stimulus strength across discrete trials based on the observer's responses. The observer is typically restricted to a limited set of responses, and the stimuli are varied according to a predefined algorithm.

In visual field testing, the observer either presses or does not press a button within a fixed time window following the presentation of a light increment in the visual field (a yes/no response). The relationship between stimulus strength and response probability is modeled by a psychometric function, which characterizes the likelihood of a "yes" response as a function of stimulus strength. These models yield an estimate of the threshold, defined as the stimulus strength at which the observer detects the stimulus with a probability of 50\%.

The most straightforward method for estimating this threshold is the method of constant stimuli, in which stimuli are presented multiple times at several discrete, fixed intensities around the anticipated threshold. This approach yields an accurate estimate of the psychometric function, which is typically modeled using a cumulative distribution function (CDF), such as the Gaussian CDF. However, this method is inefficient and requires a large number of trials, since stimulus levels far from the threshold provide little information. Long test durations negatively affect attention, thereby reducing both the accuracy and precision of the threshold estimates.

To improve efficiency, adaptive algorithms have been developed to reduce the number of stimulus presentations with minimal compromise in accuracy. A commonly used example is the staircase algorithm, in which the stimulus intensity decreases after a "seen" response and increases after a "not seen" response. The step size is halved after each reversal (i.e., a change in response direction). More sophisticated algorithms balance precision and test duration, often incorporating information from adjacent locations in the visual field. A notable example is the Swedish Interactive Threshold Algorithm (SITA) used in the Humphrey Field Analyzer.

At the conclusion of the test, the inverse of the contrast threshold, $\Delta L_{\text{threshold}}$, is recorded at each location using a logarithmic decibel (dB) scale. This scale is defined as the attenuation from the maximum possible stimulus contrast, $\Delta L_{\text{max}}$:

\begin{equation}
dB = -10\ \rm log \left (\frac{\Delta L_{\rm thr}}{\Delta L_{\rm max}} \right)\ .
\end{equation}

For common devices such as the Humphrey Field Analyzer and the Octopus 900, the maximum luminance differential is $\Delta L_{\text{max}} = \frac{10{,}000\ \text{apostilbs}}{\pi} \approx 3183.1\ \text{cd},\text{m}^{-2}$.

The visualFields package was developed to analyze data from static perimetry, where thresholds are measured at fixed, discrete locations in the visual field. Kinetic perimetry, in which a stimulus of constant luminance is moved across the field to identify isosensitivity contours, is outside the scope of this package.

Static perimetry aims to estimate the hill of vision as accurately as possible within the constraints of clinical practice. The most common form is standard automated perimetry (SAP), which is performed inside a dome-shaped device (a Ganzfeld perimeter) to ensure a uniform distance between the eye and all stimulus locations. In contrast, campimetry uses a flat screen and may become more common with the increasing availability of computer screens and virtual reality devices for telemedicine.

\subsection{How is perimetry performed?}

In a typical SAP test, the patient is seated comfortably in front of a perimeter and places their head on a chin rest while looking into a white Ganzfeld dome. The room is dimly lit and quiet, and the patient is briefed by an experienced technician before the examination. During the test, the patient fixates on a central target (e.g., a dot, cross, or diamond), and presses a button whenever a light stimulus is perceived.

Stimuli are presented briefly (typically 100–200 ms), minimizing the opportunity for eye movement. A response is only considered valid if it occurs within a defined time window following the stimulus. A computer presents stimuli at discrete locations in a grid, in randomized order. The stimulus intensity at each location is adjusted adaptively based on the patient' responses. Because of randomization, the patient cannot anticipate where the next stimulus will appear.

The figure below shows the commonly used 24-2 grid of test locations. The gray ellipse represents the anatomical blind spot; the red points fall within this region and are expected to show no sensitivity.

The grid, stimulus size, presentation duration, and intensity algorithm remain constant throughout the test and together define the perimetry program. It is important to note that results from different perimetry programs are not directly comparable.

\subsection{False negatives and false positives}

Deviations from the expected psychometric function may arise due to observer inattention or short-term threshold fluctuations. In diseases like glaucoma, short-term variability is often elevated in damaged regions of the visual field. Response quality is typically assessed by:

\begin{enumeration}
  \item [False negatives (FNR)] Missed responses to stimuli that were previously seen.
  \item [False positives (FPR)] Responses when no stimulus is presented
  \item [Fixation losses] Responses to stimuli presented within the blind spot
\end{enumeration}

These metrics help assess the reliability of a test.

\subsection{Clinical applications of perimetry}

In clinical settings, perimetry is used to detect and monitor visual field defects or scotomas, which can arise from damage anywhere along the visual pathway—from the ocular media (cornea, lens, vitreous), to the retina, optic nerve, or visual cortex.

The spatial pattern of visual field loss often provides diagnostic clues. For instance, a right occipital lobe infarct can result in left homonymous hemianopia—complete loss of the left visual field in both eyes, with a sharp border along the vertical meridian. Conversely, glaucoma typically presents as arcuate defects, often beginning in the upper or lower hemifield, reflecting characteristic damage to the optic nerve head.

Perimetry supports not only diagnosis but also evaluation of functional impact (e.g., fitness to drive) and disease progression monitoring.

%% -- Methods ------------------------------------------------------------------

\section{Methods} \label{sec:methods}

\subsection{Installation}

The \pkg{visualFields} package is available from CRAN under the Apache 2.0 license and can be installed with:

<<eval=FALSE>>=
install.packages("visualFields")
@

The latest development version can be installed from GitHub using:

<<eval=FALSE>>=
library(devtools)
install_github("imarinfr/vf1/source")
@

\subsection{Grid patterns}

Test locations are defined by location maps (\texttt{locmap}), which specify the spatial coordinates of stimulus presentation points in degrees of visual angle. These maps reflect the layout used by visual field testing devices. When analyzing data, the correct \texttt{locmap} must be specified.

By default, the \texttt{24-2} pattern is used, consisting of 54 regularly spaced locations across the central visual field.

<<>>=
library(visualFields)
default_locmap <- getlocmap()
str(default_locmap)
@

Each \texttt{locmap} contains:
\begin{itemize}
  \item A coordinate table with $x$- and $y$-positions (in degrees),
  \item A vector \texttt{bs} indicating locations corresponding to the physiological blind spot.
\end{itemize}

Other patterns are available in the package, including the \texttt{10-2} grid:

<<>>=
ten_two_locmap <- locmaps$p10d2
str(ten_two_locmap)
@

All available patterns can be listed with:

<<>>=
names(locmaps)
@

If the blind spot is outside the tested region (e.g., in the 10$^\circ$ pattern) or is skipped (e.g., in the Octopus G1), the \texttt{bs} field is set to \texttt{numeric(0)}.

\subsection{Loading data}
The visualField package contains some example data. This dataset contains the results of 42 visual field tests of one patient (id: sample1). The patient has primary open-angle glaucoma (type: pwg).

<<>>=

str(vfpwgSunyiu24d2[, 1:10])

@

\subsection{Loading data}

The package includes example data from a glaucoma patient (\texttt{vfpwgSunyiu24d2}), consisting of 42 visual field tests.

<<>>=
str(vfpwgSunyiu24d2[, 1:10])
@

Each row represents a monocular test. The eye is labeled using Latin abbreviations: OD (right eye), OS (left eye), and OU (both eyes). Initial columns store patient information and reliability metrics. Actual test values begin at the column number stored in the \texttt{locini} variable:

<<>>=
getlocini()
getvfcols()
vfpwgSunyiu24d2[1, getvfcols()]
@

No columns should appear after these tsest values. Use \texttt{vffilter} to select specific tests and \texttt{vfisvalid} to verify data structure:

<<>>=
example1 <- vffilter(vfpwgSunyiu24d2, id == "sample1" & eye == "OD")[1, ]
example1$newVariable <- "invalid"
vfisvalid(example1)
@

\subsection{Statistical analysis of contrast thresholds}

\subsubsection{Defining defective locations}

Sensitivity is measured in decibels (dB), derived from contrast thresholds. Sensitivity varies:
\begin{itemize}
  \item Intra-individually (test-retest variability),
  \item Inter-individually (e.g., with age),
  \item By eccentricity.
\end{itemize}

To detect abnormal points, we compare observed sensitivities with an age-corrected mean normal field. These comparisons require a \textbf{normative dataset} and location-wise \textbf{age-linear models}.

The difference between observed and normal values is the \textbf{total deviation (TD)}. In this package, negative values indicate lower-than-normal sensitivity, following the Humphrey Field Analyzer convention. For perimeters that reverse this definition (e.g., Octopus), users must invert the sign.

To reveal focal defects masked by generalized depression (e.g., due to cataract), a \textbf{pattern deviation (PD)} is computed by subtracting a general height (GH) estimate from the TD. For 24-2, GH is defined as the 7th highest TD value.

\subsubsection{Normative datasets}

The package includes three normative datasets:

\begin{itemize}
  \item SUNY-IU dataset for 24-2 with Goldmann size III \citep{IMF:Mar2013b}
  \item Iowa PC26 and Peri datasets for Goldmann size V \citep{IMF:Marin2018c}
\end{itemize}

<<>>=
str(vfctrSunyiu24d2[, 1:10])
str(vfctrIowaPC26[, 1:10])
str(vfctrIowaPeri[, 1:10])
@

To build the normative model:

<<>>=
nv <- nvgenerate(vfctrSunyiu24d2)
setnv(nv)
@

The normative object \texttt{nv} includes coefficients of age-linear models:

<<>>=
print(nv$agem$coeff)
@

The expected field at age 50 is:

<<>>=
age <- 50
print(nv$agem$model(age))
@

Blind spot locations are returned as \texttt{NA}.

\subsubsection{Total deviation}

Total deviation is the difference between observed and expected sensitivity:

<<>>=
example2 <- vffilter(vfpwgRetest24d2, id == "1", eye == "OD")[1, ]
age <- example2$age[1]
normal_values <- getnv()$agem$model(age)[1:10]
example2[, getvfcols()[1:10]] - normal_values
@

Or, use the automated function:

<<>>=
td <- gettd(example2)
print(td[, getvfcols()[1:10]])
@

\subsubsection{Pattern deviation}

Pattern deviation is obtained by subtracting the general height:

<<>>=
gh <- getgh(td)
pattern_defects <- td[, getvfcols()[1:10]] - gh
@

Or automatically:

<<>>=
pd <- getpd(td)
print(pd[, getvfcols()[1:10]])
@

\subsubsection{Probability values}

Even healthy eyes may show small deviations. To interpret these values, we calculate the probability that a deviation reflects pathology using empirical distributions from the normative data \citep{IMF:Hei1987a, IMF:Heijl1991}.

<<>>=
print(getnv()$lut$probs)
print(gettdp(td)[, getvfcols()[1:10]])
print(getpdp(pd)[, getvfcols()[1:10]])
@

Probabilities less than 0.05 suggest the location is likely abnormal.

\subsection{Global indices}

Global indices summarize the visual field:

<<>>=
gl <- getgl(example2)
print(gl[, -(1:getlocini() - 1)])
@

\begin{itemize}
  \item \texttt{msens}: Mean sensitivity (MS)
  \item \texttt{ssens}: SD of sensitivity
  \item \texttt{tmd}: Mean total deviation (MD)
  \item \texttt{tsd}: SD of total deviation
  \item \texttt{pmd}: Mean pattern deviation
  \item \texttt{psd}: SD of pattern deviation
  \item \texttt{gh}: General height
  \item \texttt{vfi}: Visual field index (VFI) \citep{IMF:Ben2008}
\end{itemize}

Associated probabilities:

<<>>=
print(getglp(gl)[, -(1:getlocini() - 1)])
@

%% -- Results ------------------------------------------------------------------

\section{Results} \label{sec:results}

\subsection{Plotting the visual field}

There are various ways to visualize perimetric data. These visualizations should be interpreted as simplified representations of the hill of vision.

Standard displays include color-coded probability maps, graphical representations of the blind spot, and border enhancements that encode diagnostic information. For example, 	exttt{vfplot} with the argument 	exttt{"td"} generates plots that require normative data on differential light sensitivity and the probabilities of deviations from these norms. This information is included for the Humphrey Field Analyzer patterns but must be provided separately for other perimeters.

By convention, when displaying both eyes side-by-side, the left eye appears on the left and the right eye on the right. This reflects the patient's visual fields, with blind spots positioned temporally. This is in contrast to structural imaging, which is typically displayed as viewed by the examiner.

It is important to specify the type of data represented in the visual field tables. The default is set to \textbf{total deviation} (	exttt{td}).

<<fig=TRUE>>=

vfplot(example2)

@

In this plot, yellow indicates a probability $<$ 0.05, orange $<$ 0.02, red $<$ 0.01, and dark red $<$ 0.005.

A gallery of all available plot types is available at \url{https://rpubs.com/huchzi/1307927}.

\subsection{Longitudinal analyses}

Monitoring visual function over time is a key application of perimetry in managing glaucoma.

Sensitivity measurements naturally fluctuate between tests. This variability increases in eyes with glaucoma, especially at affected locations. Hence, two tests showing differences cannot alone indicate progression. Instead, statistical analysis across a series of tests is required to detect significant change.

Progression analysis methods fall into two broad categories: \textbf{event-based} and \textbf{trend-based} approaches. These may further be classified by their reliance on population-based normative data, mathematical models of progression, or model-free methods.

Event-based methods (not implemented in \pkg{visualFields}) compare a test to a baseline and flag change if the sensitivity reduction is unlikely ($p < 0.05$) based on normative variability, and if confirmed in subsequent tests.

Trend-based methods assume slower change and analyze all tests in a series. Though less intuitive for clinicians, these methods are statistically robust and reflect real-world progression patterns.

To illustrate, we select a time series of 27 visual fields from one eye:

<<>>=
example3 <- vffilter(vfpwgSunyiu24d2, id == "sample1" & eye == "OS")
@

\subsection{Plotting progression}

Example plots used for monitoring progression are available in the gallery: \url{https://rpubs.com/huchzi/1307927}.

\subsection{Statistical analysis}

Statistical progression analysis may be performed via:
\begin{itemize}
\item \textbf{Global linear regression} (e.g., on MD)
\item \textbf{Pointwise linear regression} (PLR)
\end{itemize}

The \texttt{glr()} function estimates a regression model for global indices. For the example series, the patient loses \texttt{r round(abs(glr(getgl(example3))$sl), 2)} dB/year, with $p < \texttt{r format(ceiling(1000 * glr(getgl(example3))$pval) / 1000, nsmall = 3)}$.

Pointwise linear regression is performed using \texttt{plr()}, resulting in one slope and $p$-value per location:

<<>>=
prog1 <- plr(example3)
str(prog1, max.level = 1)
print(sum(prog1$pval[-getlocmap()$bs] < 0.05))
@

To visualize these results:

<<fig=TRUE>>=
vfplotplr(example3)
@

In this display, yellow indicates $p < 0.05$, orange $< 0.02$, red $< 0.01$, and dark red $< 0.005$.

PLR-based criteria (e.g., 3 or more progressing points) are clinically useful but lack explicit control for specificity. \textbf{Permutation of Pointwise Linear Regression (PoPLR)} addresses this by combining the 52 $p$-values into a single $S$-statistic (per Fisher's method) and comparing it to a null distribution from permuted series [@IMF:Ole2012; @IMF:Marin2021].

<<>>=
prog2 <- poplr(example3)
str(prog2, max.level = 1)
@

The null distribution and observed statistic:

<<>>=
print(prog2$csr)
print(prog2$csrp)
print(prog2$csl)
print(prog2$cslp)
@

Visualization:

<<>>=
hist(prog2$cstats$cslall, xlab = "S-values", xlim = c(0, 200))
abline(v = prog2$csl, col = "red", lwd = 2)
@

\subsection{Single field reports}

Static reports and Shiny applications can be generated:

<<eval=FALSE>>=
vfsfa(example2, file = "test.pdf")
vfsfashiny(example2)
@

\subsection{Structure-function correlation}

Anatomical modeling aids comparison between structural imaging and functional testing in glaucoma.

The ganglion cell bodies stimulated by a visual field location are displaced from the photoreceptor input region, especially in the central field. This displacement is modeled in \pkg{visualFields} based on Montesano et al. [@IMF:Montesano2020].

<<>>=
locmap <- locmaps$p10d2
gcmap <- vf2gc(locmap$coord)
@

A plot of the 10-2 grid and corresponding ganglion cell bodies:

<<echo=TRUE, fig=TRUE>>=

plotting code from original omitted for brevity

@

Nerve fiber paths from each location to the optic disc can also be modeled, using Jansonius' framework [@IMF:Jan2009; @IMF:Jan2012].

<<>>=
psi23 <- loc2psi(vf2gc(locmaps$p24d2$coord[23,]))
ang23 <- psi2oct(psi23)
print(ang23 - 360)
@

\subsection{Progression reports}

Automated reports can also be generated for progression series:

<<eval = FALSE>>=
vfspa(example3, file = "test.pdf")
vfspashiny(example3)
@

\subsection{DICOM support}

DICOM standards for static perimetry are defined in Supplement 146. The package includes preliminary functions for reading HFA-generated DICOM files, but exporting to DICOM is not yet supported.

\subsection{Support for other perimeters}

Perimetry conventions vary across manufacturers. The package includes normative data for Humphrey 24-2 (Goldmann III) and Iowa full-field perimetry with Goldmann V [@IMF:Marin2018c]. The \texttt{loadoctopus} function provides partial support for Octopus G1 fields, but normative support is incomplete.

Users may provide custom normative datasets using \texttt{nvgenerate()} and \texttt{setnv()}.

\subsection{Setting the environment}

Each analysis requires environment variables:
\begin{itemize}
\item \texttt{nv}: normative values
\item \texttt{locmap}: test grid
\item \texttt{gpar}: graphical parameters
\item \texttt{locini}: first sensitivity column
\end{itemize}

<<>>=
print(names(locmaps))
print(names(normvals))
print(names(gpars))
@

These must be consistent. For example:

<<>>=
setlocmap(locmaps$pPC26)
setnv(normvals$iowa_PC26_pw)
setgpar(gpars$pPC26)
setlocini(24)
@

To reset to default (Humphrey 24-2):

<<>>=
setdefaults()
@

\subsection{Custom configurations}

Custom test structures must:
\begin{itemize}
\item Start with columns: \texttt{id}, \texttt{eye}, \texttt{date}, \texttt{time}
\item Include \texttt{age}, optionally \texttt{fpr}, \texttt{fnr}, \texttt{fl}
\item Have sensitivity columns named \texttt{l1}--\texttt{lk}
\end{itemize}

To import custom locations:

<<eval=FALSE>>=
g1 <- list(coord = read.csv("./g1.csv"), name = "G1", desc = "G1 map", bs = numeric())
setlocmap(g1)
setgpar(vfgpar(g1$coord))
vfplot(vfread("./vfg1.csv"), type = "s")
@

If normative data exist, use \texttt{vfread()}, \texttt{nvgenerate()}, and \texttt{setnv()} to enable deviation computations.

%% -- Summary and discussion ---------------------------------------------------

\section{Summary and discussion} \label{sec:summary}

The \pkg{visualFields} package provides a robust suite of tools for statistical analysis and visualization of visual field data. It supports single-field reports, progression analysis, anatomical modeling, and customization for non-standard perimeters. As part of the Open Perimetry Initiative, it aims to foster reproducibility and transparency in perimetry research. Future development could focus on expanding normative datasets, full DICOM integration, and extended support for additional testing strategies and devices.

%% -- Acknowledgements ---------------------------------------------------

\section{Acknowledgments}
The visualField's package would not have existed if it wasn't for the important contribution of many contributors who partially funded the development of the package, and/or contributed datasets, code, and above all insight on visual fields analysis and about perimetry and visual sciences at large. Huge thanks to:
  - William H Swanson
  - Michael Wall
  - Andrew Turpin
  - Paul H Artes
  - Giovanni Montesano
  - Mitchell W Dul

%% -- Bibliography -------------------------------------------------------------

\bibliography{references}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
