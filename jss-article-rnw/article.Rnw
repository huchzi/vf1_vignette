\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}

<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library("MASS")
@


%% -- Article metainformation (author, title, ...) -----------------------------

\author{Cord Huchzermeyer~\orcidlink{0000-0002-0408-8981}\\Department of Ophthalmology, University Hospital Erlangen
   \And Iván Marín-Franch\\Computational Optometry}
\Plainauthor{Cord Huchzermeyer, Iván Marín-Franch}

\title{visualFields 1.0.7: Tools for Analyzing the Field of Vision in \proglang{R}}
\Plaintitle{visualFields 1.0.7: Tools for Analyzing the Field of Vision in R}
\Shorttitle{visualFields 1.0.7 in \proglang{R}}

\Abstract{
  The \pkg{visualFields} package is part of the Open Perimetry Initiative (OPI), 
  a standard for interfacing with visual field testing machines. This article 
  introduces the package, which provides tools for analyzing the field of vision, 
  including visualization, statistical analysis, and clinical interpretation of 
  visual-field loss and its change over time.
}

\Keywords{visualFields, Open Perimetry Initiative, visual field analysis, \proglang{R}}
\Plainkeywords{visualFields, Open Perimetry Initiative, visual field analysis, R}

\Address{
  Cord Huchzermeyer\\
  Department of Ophthalmology, University Hospital Erlangen \\
  E-mail: \email{c.huchzermeyer@posteo.de}\\
  \\
  Iván Marín-Franch\\
  Computational Optometry\\
  E-mail: \email{ivan@example.com}\\
  URL: \url{https://www.computationaloptometry.com/}
}

\begin{document}
%%\SweaveOpts{concordance=TRUE}


%% -- Introduction -------------------------------------------------------------

\section[Introduction: Visual Fields in R]{Introduction: Visual Fields in \proglang{R}} \label{sec:intro}

The Open Perimetry Initiative (OPI) \citep{IMF:Tur2012, IMF:Marin2022a} is a standard for interfacing with visual field testing machines (perimeters). It specifies basic functions that allow many visual field tests to be constructed. As of October 2017, it is fully implemented on the Octopus 900 and partially on the Heidelberg Edge Perimeter, the Kowa AP 7000, the CrewT IMO, and the Centervue Compass.

The \pkg{visualFields} package, part of the OPI, is a collection of tools for analyzing the field of vision. It provides a framework for the development and use of innovative methods for visualization, statistical analysis, and clinical interpretation of visual-field loss and its change over time.

\subsection{What is the visual field?}

The visual field of an eye is the extent of the world that can be seen. It refers to both the central and the peripheral vision. It is measured in degrees of visual angle, with the center of vision being $0^\circ$, points on the temporal and superior regions of the visual field being positive angles, and those in the inferior and nasal being negative. In healthy eyes, the sensitivity to light contrast decreases as the visual angle increases (or as it is commonly said in perimetry, eccentricity). The difference in light sensitivity over the visual field as a function of eccentricity is known as Traquair's \emph{hill of vision} \citep{IMF:Traquair1938}. The figure below shows the hill of vision as rendered by Aulhorn \& Harms \citep{IMF:Aul1967}.

\begin{figure}[t!]
\centering
\includegraphics[width=0.75\textwidth]{AulhornHillOfVision.png}
\caption{\label{fig:hill} Hill of vision as rendered by Aulhorn \& Harms.}
\end{figure}

\subsection{What is visual field testing?}

Visual field testing measures a patient's visual sensitivity at different locations of the visual field. Its purpose is to reconstruct as best as possible within the confines and limitations of a clinical setting the \textbf{hill of vision}. The most common type of visual field testing is \textbf{static automated perimetry (SAP)}, which is performed with in a dome-shaped device, so that the distance between the stimulus and the eye equal for all locations within the visual field. In contrast, \textbf{campimetry} is performed with a flat screen. [CAMPIMETRY MAY BE USED MORE OFTEN IN THE FUTURE BECAUSE COMPUTER SCREENS/ VR DEVICES MAY BE USED FOR TELEMEDICINE; LEAVE IT?]

Usually, perimetry tests the ability to detect increments in stimulus luminance with respect to the background with an achromatic (not colored) stimulus. This is a form of perimetry known as \textbf{white-on-white perimetry}. However, theoretically, other aspects of vision can be tested at different locations (ability to discriminate dots that are very close to each other, ability to discriminate similar colors, contrast sensitivity). The figure below shows the most common grid of locations tested during {SAP}. The gray ellipse corresponds to the blind spot of the hill of vision and, therefore, the red dots are expected to have no sensitivity.

<<echo=FALSE, fig=TRUE>>=

library(visualFields)
library(plotrix)

default_locmap <- getlocmap()

plot(x = default_locmap$coord$x, 
     y = default_locmap$coord$y, 
     type = "n", 
     asp = 1,
     xlim = c(-30, 30),
     ylim = c(-34, 34),
     yaxt = 'n',
     xaxt = 'n',
     bty = 'n',
     xlab = "",
     ylab = "",
     main = "24-2 grid of test locations")
lines(-c(30, 2.5), c(0, 0), lwd = 2, col = "lightgray")
lines(c(2.5, 30), c(0, 0), lwd = 2, col = "lightgray")
lines(c(0, 0), -c(30, 2.5), lwd = 2, col = "lightgray")
lines(c(0, 0), c(2.5, 30), lwd = 2, col = "lightgray")
lines(x = c(-2.5, 2.5), y = c(0, 0), lwd = 1.5)
lines(x = c(0, 0), y = c(-2.5, 2.5), lwd = 1.5)
for(r in c(10, 20, 30))
  draw.circle(0, 0, r, lwd = 2, col = NA, border = "lightgray")
draw.ellipse(15, -1.5, 2.75, 3.75, col = "gray", border = NA)
text(x = 0, y = -34, "horizontal eccentricity [degrees]")
text(x = -34, y = -0, "vertical eccentricity [degrees]", srt = 90)
text(x = 31, y = 0, "30\u00b0", adj = c(0, 0.5))
text(x = 0, y = 31, "30\u00b0", adj = c(0.5, 0))
points(x = default_locmap$coord$x[-default_locmap$bs],
       y = default_locmap$coord$y[-default_locmap$bs])
points(x = default_locmap$coord$x[default_locmap$bs],
       y = default_locmap$coord$y[default_locmap$bs],
       col = "red", pch = 19)

@

The visual fields package was created to analyze data from \textbf{SAP}. In SAP, the goal is to quantify sensitivity by increasing and decreasing the light differential (or contrast) between stimulus and background and asking the observer to press the button when they detect the presence of the visual stimulus. The contrast threshold is determined at each location of the visual field as the one for which the observer is able to detect the presence of the stimulus 50\% of the times. Such thresholds are estimated at a fixed number of locations forming a regular grid as the one in the figure above. 

There is another common form of perimetry, \textbf{kinetic perimetry}, where a light spot is moved from the periphery towards the center along a number of meridians. In this form of perimetry the location where the spot is first detected by the subject is noted and those points at different meridians are connected to find isopters of equal sensitivity on the retina. The statistical analysis for this form of perimetry is very different than for static perimetry and beyond the scope of this visualFields package.


\subsection{Performing visual field tests}
For the typical visual field test, an observer (usually a patient in an ophthalmology or optometry clinic) is comfortably seated in front of a perimeter and puts his head on a chin rest looking into a white Ganzfeld dome (or hemisphere). The perimeter is located in a dimly lit, calm room and the observer has been explained what to do by an experienced technician before the examination. In his hand, the observer has access to a clicker.

Observers now look at a fixation target (a dot, a cross, a diamond, or other) right in front of them in the center of the dome and are presented visual stimuli over their visual field. Observer are to press the clicker any time a stimulus appears anywhere in the dome These lights are presented only for a short time span (typically 100-200ms), so that the observer has no time to shift his gaze to the stimulus. A press of the clicker will be linked to a presentation when it occurs within a given time window after the presentation. A computer will present stimuli several times at different locations in a grid pattern and in a spatially random order. For each location, the stimulus contrast will be decreased if the observer responded to the previous response and increased if not.

At the end of the test, the inverse of the contrast threshold, $\Delta L_{\rm threshold}$ at each location is recorded in a decibel scale (dB). This dB scale is normally defined as attenuation from the maximum stimulus possible $\Delta L_{\rm max}$ as:
\begin{equation}
dB = -10\ \rm log \left (\frac{\Delta L_{\rm thr}}{\Delta L_{\rm max}} \right)\ .
\end{equation}
For the most common devices, the Humphrey Field Analyzer and the Octopus 900, the maximum luminance differential $\Delta L_{\rm max}$ is $10000\ (\rm apostilb) / \pi = 3183.1\ cd\ m^{-2}$.

These are the data expected by the visualFields package for statistical analysis and generation of visualization devices.

\subsection{Psychophysical testing}
Psychophysical tests systematically measure the relationship between physical stimulus strength and the subjective perception. This is performed by varying the stimulus and asking the observer to communicate his perception with a limited number of allowed responses. In visual field testing, the observer usually presses a button when a light spot is perceived. 

The relationship between stimulus and perception is analyzed using mathematical model. Commonly, these models result in an estimate of a \textbf{threshold}, which denotes either the absolute stimulus strength that can just barely be perceived or the smallest difference that can be perceived as different. 

Real world scenarios where perception is close to threshold include going through a dark forest on a cloudy night or seeing the car in front through a dense fog. Stimuli are not clearly seen when close to threshold. For this reason, patients sometimes feel that lengthy visual field testing is tedious and that it is as an unreliable examination. The latter is not clearly correct when fluctuations are taken into account and data are analyzed with appropriate statistical methods.

\subsection{Grid patterns}
The spatial position of the points $l_1$ to $l_k$ in the visual field is found in the location map (locmap) and depends on the pattern used by the perimeter. When analyzing data, you need to specify the locmap.

By default, the 24-2 pattern (shown in the previous figure) is used, which consists of 54 locations that are equally spaced across the field.

<<>>=
str(default_locmap)
@

Beside a name and a description, a locmap dataset contains a coordinate table with the x- and y-coordinates of the locations measured in degrees, and the id of the points that cover the physiological blind spot (the id is the number x in $l_x$ and corresponds to the row in the coord table).

Other grid patterns are also defined in the package. For instance, the 10-2 grid:

<<>>=
ten_two_locmap <- locmaps$p10d2
str(ten_two_locmap)
@

And many others:

<<>>=
names(locmaps)
@

Locations of the locmap that cover the blind spot are reported in the locmaps lists under the variable bs. If the blind spot is outside the pattern (for example in the 10° visual fields) or is spared by the grid as in the Octopus G1 pattern, the list item bs is set to `r numeric(0)`.

The grid, the stimulus size, presentation time and the algorithm responsible for varying intensities remain constant throughout the examination and are called a perimetry program. Not that examinations performed with different programs cannot be directly compared.

\subsection{Measurements}
Although usually not seen in visual field data, the most elementary unit of a static visual field test is a subject's response. It consists of the constant stimulus parameters (size, presentation time, background luminance), the stimulus location, the stimulus intensity and whether the subject pressed the button within a predefined time window to indicate that he saw the stimulus.

Below a certain \textbf{threshold} luminance, a stimulus is usually not perceivable, above the threshold, the stimulus is usually perceived. However, close to threshold, a stimulus is not always reliably perceived. By definition, the threshold is the luminance of the stimulus where the subject will see the stimulus with a probability of 50\%.

The most straightforward to measure such a threshold would be to present stimuli several time at a number different, fixed stimulus strengths. This method is called the method of \textbf{constant stimuli} and results in the \textbf{psychometric function}, which is usually modeled with a cumulative distribution function (CDF), for example a Gaussian CDF. However, this is not the most effective way to estimate a threshold, because stimulus strength far from the threshold will have probabilities to be seen that are close to either 0\% or 100\%. Testing these strengths several times does not yield much information.

Therefore, advanced algorithms were developed for reducing the number of stimulus presentations with limited trade-off concerning the accuracy of the measurements. A staircase algorithm where the intensity is decreased by a certain step size when the stimulus was seen, increased when not seen, and the step size is halved upon each revearsal (seen to not seen or vice versa) is a more efficient algorithms that is frequently used. More efficient algorithms usually make a trade-off between precision of the threshold estimate and test time, and often incorporate information on responses in neighboring locations into the algorithm. Examples include the Swedish Interactive Threshold Algorithm (SITA) of the Humphery Perimeters. Note that long test times negatively affect attention and therefore both accuracy and precision of the threshold estimates.

\subsection{False negatives and false positives}

Residual deviation from the psychometric function may occur due to inattention of the observer but also due to short-term fluctuation of the threshold. For example, it has been shown that the threshold underlies short-term fluctuates in the areas where light sensitivity was negatively affected by glaucoma, a disease of the optic nerve.

When the observer does not see a stimulus that is clearly above a level that has been seen before, this is called a false negative response (fnr). In contrast, when the subject presses the button although no stimulus is presented, this is a false positive response (fpr).

The cooperation of the subject is also tested in some perimeters by presenting deliberately presenting a stimulus at the location of the blind spot. If the subjects sees that stimulus, it must be assumed that he did not fixate correctly (fixation loss) and that the reliability of the field is decreased.

\subsection{Clinical applications of perimetry}
In clinical practice, visual field testing is used to identify decreases in visual function caused by disease. Such \textbf{visual field defects} or \textbf{scotomas} can be caused by diseases that affect tissue anywhere along the optic pathway. This ranges from the optic media (cornea / lens / vitreous) which transmit light, to the retina, which detects lights and preprocesses visual information, to the optic nerve, which transmits information, and up to the visual cortex.

Often, clinicians can draw reliable conclusions about the localisation of the disease by the pattern of the visual field defects. For example, an infarction of the right visual cortex leads complete blindness in the left hemispheres of both eyes with a very distinct border along the vertical meridian. Therefore, the patient does not perceive anything to the right of the point he looks at. On the other side of the vertical meridian the visual field is normal. In contrast, patients with glaucoma start with areas of slightly decreased light sensitivity often in the upper or lower hemifield with a bow-shaped (arcuate) pattern cause by the localisation of damage in the optic nerve head.

Visual field tests can be used to diagnose disease, to appraise the functional consequences of disease (for example: can the patient still drive a vehicle?), and to monitor progression.

[THIS SEEMS TO BE A BIT OUF OF PLACE, BUT I PREFER NOT TO EDIT THIS PART MYSELF]
The most advanced statistical methods have been created for monitoring glaucoma progression. The open-angle glaucomas are a group of slowly progressing, chronic neurodegenerative diseases of the optic nerve, often caused by increased eye pressure. Patients need consequent monitoring over many years and slight changes in the visual field must be detected reliably. Therefore, many of the functions of the visualField package focus on glaucoma research.

%% -- Methods ------------------------------------------------------------------

\section{Methods} \label{sec:methods}

\subsection{Installation}

The package is available on CRAN under the Apache 2.0 license and can be installed with the following command:

<<eval=FALSE>>=

install.packages("visualFields")

@

To install the newest version of the package, run:

<<eval=FALSE>>=

library(devtools)
install_github("imarinfr/vf1/source")

@

<<echo=FALSE>>=

library(ggplot2)
library(plotrix)

@

\subsection{Loading data}
The visualField package contains some example data. This dataset contains the results of 42 visual field tests of one patient (id: sample1). The patient has primary open-angle glaucoma (type: pwg).

<<>>=

str(vfpwgSunyiu24d2[, 1:10])

@

The first columns characterize the patient, the time and duration of the examination, the diagnosis, and the reliability parameters 'false positive responses', 'false negative responses' and 'fixation losses'.

Each row corresponds to one visual field test. Visual field testing is performed monocularly (one eye at a time), so that two examinations exist for each date. The abbreviations for the laterality ('eye') is derived from latin (OD: right eye = oculus dexter, and OS: left eye = oculus sinister), when both eyes are examined, the abbreviation is OU.

The environment variable locini contains the number of the first column that contains the actual visual field date. Each column $l_{x}$ corresponds to one of {k} locations in the visual field test. A concise way to select the columns $l_1$ to $l_{k}$ is to use the \textbf{getvfcols} function.

<<>>=

getlocini()
getvfcols()

vfpwgSunyiu24d2[1, getvfcols()]

@

There mustn't be any columns after these columns. Use the \textbf{vffilter} function to select specific fields and the \textbf{vfisvalid} function to check whether a table fulfills the criteria. The latter will also tell you what the problem is when it doesn't.

<<>>=

example1 <- vffilter(vfpwgSunyiu24d2, 
                     id == "sample1" & 
                       eye == "OD")[1, ]

example1$newVariable <- "not valid"

vfisvalid(example1)

@

\subsection{Mathematical derivatives of contrast thresholds for statisitcal analysis}

\subsubsection{Identifying defective locations on the visual field}

As mentioned earlier, the sensitivity in dB at each location is calculated from the contrast threshold relative to the maximal contrast.

The sensitivity to light fluctuates considerably between measurements in the same observer (test-retest variability ---and more as the disease progresses) and between observers (inter-individual differences). They also decrease at different rates depending on the eccentricity with age.

With these predictable and unpredictable differences in the pointwise sensitivity measurements, how can we provide tools and reports to aid the clinical assessment of the visual field? Or more to the point, how can we discriminate between healthy locations and locations that are damaged or suspected of being damaged? Clinically, it is more useful to compute and report the deviations from an age-corrected mean normal visual field, since the identification of spatial patterns of damage becomes easier, thus facilitating the clinical assessment of the visual field.

But this analysis requires the use of a \textbf{normative dataset} from which to obtain models describing the age effect on sensitivity at each location. These functions are usually linear and those \textbf{age linear models} are used to obtain the \textbf{age-corrected mean normal visual field}.

The resulting \textbf{deviations} from age-corrected mean normal visual field are also measured in dB and they are interpreted as follows. By convention, in the Humphrey Field Analyzer, a negative deviation value means that the sensitivity at that location is below mean normal. In contrast, on Octopus perimeters, negative is above and positive below mean normal (therefore, values are called \textbf{defects}). In this package, those differences are called \textbf{total deviation} and their interpretation are as for the Humphrey perimeter. In case you use visualFields with data from a different perimeter it is important to know what is the definition of \textbf{deviation} and change the sign if necessary.

In eye diseases like glaucoma, general defects that affect the whole visual field are often less relevant than focal scotomas. And often ocular opacities caused by cataract can mask such focal defects. For this reason, a statistical post-hoc correction to \textbf{total deviation} values is further applied to obtain \textbf{pattern deviation} values. The correction factor is often called the \textbf{general height} and for the 24-2 Humphrey is obtained by selecting the 7th greatest total deviation value. The \textbf{pattern deviation} values equal the \textbf{total deviation} values minus the \textbf{general height}.

\subsubsection{Normative dataset and normative references}
The visualFields package contains three datasets of healthy subjects that can be used to obtain normative age linear models and references.

The SUNY-IU dataset [@IMF:Mar2013b] for the 24-2 SITA Standard and the Goldmann Size III:
<<SUNYIU datasets>>=
str(vfctrSunyiu24d2[,1:10])
@

The Iowa dataset [@IMF:Marin2018c] for a bimodal ZEST algorithm and the Goldmann Size V:
<<Iowa datasets>>=
str(vfctrIowaPC26[,1:10])
str(vfctrIowaPeri[,1:10])
@

From these datasets, or any other dataset of healthy eyes, normative references can be computed as follows:

<<nv>>=
nv <- nvgenerate(vfctrSunyiu24d2)
@

For future use, we set `nv` as the normative values to be used in visualFields for the calculation of total and pattern deviation values and other statistical analyses.
<<setnv>>=
setnv(nv)
@

\subsubsubsection{Age linear models and mean normal visual fields}
The normative values and references stored in `nv` contains the coefficients of the age linear models:

<<agelm>>=
print(nv$agem$coeff)
@

And a function from where the age-corrected mean normal visual fields can be computed:
<<agemeannormal>>=
age <- 50
print(nv$agem$model(age))
@

Notice that the locations corresponding to the anatomical region of the blind spot all have `NA` as values, as they are excluded from the statistical analysis.

\subsubsection{Total deviation}
Total deviation is calculated from the sensitivities and from age-related normal values. These are saved in the environment variable \textbf{nv} (normal values).

<<sensitivities>>=

example2 <- vffilter(vfpwgRetest24d2, 
                     id == "1" & 
                       eye == "OD")[1,]

print(example2[, getvfcols()[1:10]])

@

<<total deviation>>=

age <- example2$age[1]

print(age)

normal_values <- getnv()$agem$model(age)[1:10]

print(normal_values)

total_defects <- example2[, getvfcols()[1:10]] - normal_values

print(total_defects)

@

These values can be automatically calculated with a dedicated function.

<<>>=

td <- gettd(example2)
print(td[, getvfcols()[1:10]])

@

\subsubsection{Pattern deviation}
Pattern deviation can be calculated after obtaining the general height.
<<gh>>=
gh <- getgh(td)
print(gh)
pattern_defects <- td[, getvfcols()[1:10]] - gh
print(pattern_defects)
@

These values can be automatically calculated with a dedicated function.

<<pattern deviation>>=

pd <- getpd(td)
print(pd[, getvfcols()[1:10]])

@

\subsubsection{Total and Pattern deviation probabilities}
As mentioned psychophysical sensitivity values vary considerably from test to test and between subjects Therefore, even in perfectly average eyes deviations will be different from zero most of the time. Given a visual field from a patient, the clinician has to know if a given deviation is likely to be caused by disease as opposed to normal retest and inter-individual variability.

The function `nvgenerate` computes for the normative dataset, the total deviation and pattern deviation values for healthy eyes and records pointwise empirical probability distribution functions [@IMF:Hei1987b] that can be used to compute the probability that a specific total deviation (or pattern deviation value) value is from a healthy location [@IMF:Hei1987a] [@IMF:Heijl1991]. Thus, a low probability implies a greater likelihood of the location being damaged. Typically (and in our example), the probabilities are categorized as
<<probability categories>>=
print(getnv()$lut$probs)
@

where `0.005` means probability $< 0.005$, where `0.01` means probability $< 0.01$, etc. A probability greater than 0.05 is considered within the normal range.

The probability values for the previous values are as follows.

<<probability maps>>=
print(gettdp(td)[, getvfcols()[1:10]])
print(getpdp(pd)[, getvfcols()[1:10]])
@

\subsection{Global indices}
Global indices summarize the visual field in a few parameters and their values and probability level can be calculated with the visualField package. The resulting table contains the visual field header data (patient id, eye, etc.) and 8 additional columns (msens, ssens, tmd, tsd, pmd, psd, gh, and vfi).

<<>>=

print(getgl(example2)[,-(1:getlocini()-1)])

@

The column `msens` is the mean sensitivity (MS); the arithmetic mean of all sensitivity values. The column `ssens` is the standard deviation of sensitivity values.

The column `tmd` is the mean deviation (MD); the arithmetic mean of all total deviation values. The column `tsd` is the standard deviation of total deviation values.

The column `pmd` is the mean of pattern deviation values. The column `psd` is the standard pattern deviation (PSD) or the standard deviation of the pattern deviation values.

The last column, `vfi`, is the visual field index (VFI) [@IMF:Ben2008], and the second to last is the general height (GH).

The probability of the observed values given that the visual field is normal can also be calculated.

<<>>=

print(getglp(getgl(example2))[, -(1:getlocini()-1)])

@

%% -- Results ------------------------------------------------------------------

\section{Results} \label{sec:results}

\subsection{Plotting the visual field}
There are different ways to visualize the perimetric results. These visualizations have to be interpreted like maps in that they represent a simplified version of the hill of vision.

The standard already contains some additional information with a border presenting a color-coded visualization of the deviation and a graphical representation of the blind spot. Note that the vfplot with the option "td" needs information on differential light-sensitivities in a normal reference population and on the probability of given deviations from these normal values. These data are included for the typical Humphrey Field Analyzer fields, but you need to collect this information if you use other perimeters.

By convention, when both eyes are presented side by side, the left eye is shown on the left and the right eye on the right. This corresponds to the visual field of the observer, so that the physiological blindspots are directed temporally (toward the temple, away from the nose) for both eyes. This is in contrast to presentation of structural data, which is usually shown like it would look in a patient sitting in front of you, where his right eye is on the observers left side.

Note that you have to specify what type of data is contained in the visual field tables. The default is set to \textbf{total deviation}, `td`.

<<fig=TRUE>>=

vfplot(example2)

@

In this graph, yellow represents probabilities < 0.05, orange probabilities < 0.02, red < 0.01, and dark red < 0.005.

A gallery with all available visual field plots is available online at \url{
https://rpubs.com/huchzi/1307927}.

\subsection{Longitudinal analyses}
Monitoring visual function over time in glaucoma patients is an essential clinical application of visual fields in ophthalmology and optometry practices. 

For several reasons, measurements will fluctuate over time. Fluctuation between measurements will be greater in eyes with glaucoma, especially in areas of glaucoma-related visual field defects. Therefore, it is not possible to compare two field tests and claim that the disease has progressed only because the second test yielded lower sensitivities.

Statistical methods and a series with a minimum number of tests are necessary in order to demonstrate disease progression in the visual fields. Statistical methods for progression in glaucoma that can be subdivided into \textbf{event-based} and \textbf{trend-based} methods. Furthermore, methods can be subdivided into those that require datasets which describe the "normal fluctuation" in a given population, those that rely on a mathematical model of visual field progression, and those that do not rely on either.

Event-based methods are not implemented in the visualFields package. Briefly, they look for progression between the most recent field and a baseline. Progression is characterized by a decrease in sensitivity with a magnitude that is unlikely (< 5\%) in the population under examination (population based data is necessary) and needs to be confirmed in further tests (usually at least two).

Trend-based methods assume that progression takes place more slowly, so that several field tests are carried out during this time span. This concept is unsettling for the clinician who wants to stop progression the first time that he sees the patient, but regularly takes place even in the case of optimal treatment. The advantage is that all measurements are taken into account, not only the baseline test and the most recent tests.

There are several tools to analyze progression with visualFields. To review them, we will select a series of 27 visual fields that were obtained over several years.

<<>>=
example3 <- vffilter(vfpwgSunyiu24d2, 
                     id == "sample1" & 
                       eye == "OS")
@

\subsection{Plotting progression}

The plot used for showing progression are shown in the gallery, which can be found at: \url{https://rpubs.com/huchzi/1307927}.

\subsection{Statistical analysis}
Statistical analysis can be performed with linear regression of global indices or with pointwise linear regression (one regression line for each location), which results in as many slopes and $p$-values as there are visual field locations (52 for the 24-2 grid after removing the two that fall on the anatomical region of the blind spot).

The \textbf{glr} function performs linear regression on global parameters. In the following example, the patient loses `r round(abs(glr(getgl(example3))$sl), 2)` dB each year and this change is statistically significant, with a $p$-value < `r format(ceiling(1000 * glr(getgl(example3))$pval) / 1000, nsmall = 3)`.

<<>>=

# md_regression <- data.frame(time = glr(getgl(example3))$years,
#            md = glr(getgl(example3))$data)
# 
# globallm <- glr(getgl(example3))
# slope <- globallm$sl
# intercept <- globallm$int
# pval <- globallm$pval
# 
# ggplot(md_regression, aes(x = time, y = md)) +
#   geom_point() +
#   geom_abline(slope = slope, intercept = intercept)
# 
# print(paste("intercept:", intercept))
# print(paste("slope:", slope))
# print(paste("p-value:", pval))

@

The `plr` function performs pointwise linear regression (i.e. linear regression for each location in the field separately). Specific parameters have to be chosen, in order to detect disease progression. For example, progression might be defined as at least 3 locations having a slope less than 0 dB / year and a $p$-value < 0.05.

<<>>=

prog1 <- plr(example3)
str(prog1, max.level = 1)

# show the total number of siginficantly progressions locations
# (out of the 52 pointwise linear regressions)
print(sum(prog1$pval[-getlocmap()$bs] < 0.05))

@

The results of `plr` can be displayed using the following: 

<<fig=TRUE>>=

vfplotplr(example3)

@
In this graphical display, yellow means that the $p$-value for this location is < 0.05, orange that it is < 0.02, red < 0.01, and dark red < 0.005.

Criteria such as the one suggested earlier based on clusters of locations significantly progressing are useful clinically but do not control for specificity. An alternative method that ensure that specificity of progression is mantained at 95\% or any other desired level is Permutation of Pointwise Linear Regression or PoPLR [@IMF:Ole2012] [@IMF:Marin2021]. For this method, all 52 $p$-values are combined into a single $S$-statistic, originally introduced by Fisher [@IMF:Fisher1925]. In order to avoid reliance on population statistics or parametric statistics. (Fisher's original work showed that such statistic followed a chi-square distribution but only if the 52 significance tests were independent of each other and the data was Gaussian, two assumptions that are far from reality.) Thus, random permutations of the series of visual fields are generated and, for each, the $S$-statistic computed. If enough random permutations are performed, the resulting set of $S$-values represent an empirical distribution for the null hypothesis that there is no progression. A combined $p$-value can then be obtained to test this hypothesis against deterioration of the visual field. The interpretation of the $p$-value is as with any significance test.

The \textbf{poplr} function yields a large list with many intermediate computations. The main result is the $S$-value and its $p$-value. Note that there is a left tailed (deterioration), a right tailed (improvement) and a two-tailed (visual field not stable) versions in the current implementation.

<<>>=

prog2 <- poplr(example3)
str(prog2, max.level = 1)

@

An improvement is highly unlikely in this series.

<<>>=

print(prog2$csr)
print(prog2$csrp)

@

In contrast, a deterioration is very likely (p < 0.001).

<<>>=

prog2$csl
prog2$cslp

@

In the histogram representing the null distribution, you can see that a $S$-value of `r round(prog2$csl)` was only very rarely found in the random permutations of the visual field series.

<<>>=

hist(prog2$cstats$cslall, xlab = "S-values", xlim = c(0, 200))
abline(v = prog2$csl, col = "red", lwd = 2)

@

\subsection{Putting everything together}
Single field analysis reports can be created as pdfs or as interactive reports with Shiny. To explore them, type in the R Console the following:

<<eval = FALSE>>=
vfsfa(example2, file = "test.pdf")
vfsfashiny(example2)
@

\subsection{Structure function correlations in glaucoma patients}
In the last years, techniques that provide detailed imaging of the retina and the optic nerve have made incredible advances. Therefore, correlation between structure and function is becoming more important than ever.

To aid comparisons between structural insult and functional defect, it is useful to understand and model the anatomy of a typical healthy eye, even if such modeling through is imperfect given the large inter-individual differences in anatomical features [@IMF:Jan2009] [@IMF:Jan2012] [@IMF:Drasdo2007] [@IMF:Montesano2020]

In glaucoma, the damage occurs in the optic nerve at the levels of the nerve fiber bundles, which consist of the axons of the retinal ganglion cells. In the retina, these cells form two layers: the ganglion cell layer that contains the cell bodies, and the retinal nerve fiber layer. However, the cell bodies of the retinal ganglion cells are displaced from the area where the photoreceptors are located that they receive input from. This displacement is relevant mostly in the center of the visual field, so it would greatly affect the structure-function comparisons on grids such as the 10-2. The following figure shows the visual field locations and the corresponding ganglion cell soma being stimulated.

<<>>=

locmap <- locmaps$p10d2
gcmap <- vf2gc(locmap$coord)

@

<<echo=TRUE, fig=TRUE>>=

plot_grid <- function() {
  lines(-c(10, 0.5), c(0, 0), lwd = 2, col = "lightgray")
  lines(c(0.5, 10), c(0, 0), lwd = 2, col = "lightgray")
  lines(c(0, 0), -c(10, 0.5), lwd = 2, col = "lightgray")
  lines(c(0, 0), c(0.5, 10), lwd = 2, col = "lightgray")
  lines(x = c(-0.5, 0.5), y = c(0, 0), lwd = 1.5)
  lines(x = c(0, 0), y = c(-0.5, 0.5), lwd = 1.5)
  for(r in c(2.5, 5, 7.5, 10))
    draw.circle(0, 0, r, lwd = 2, col = NA, border = "lightgray")
  text(x = 11, y = 0, "10\u00b0", adj = c(0, 0.5))
  text(x = 0, y = 11, "10\u00b0", adj = c(0.5, 0))
}

par(mfrow = c(1, 2))
plot(x = locmap$coord$x, 
     y = locmap$coord$y, 
     type = "n", 
     asp = 1,
     xlim = c(-10, 12),
     ylim = c(-10, 10),
     yaxt = 'n',
     xaxt = 'n',
     bty = 'n',
     xlab = "",
     ylab = "",
     main = "10-2 grid of test locations")
plot_grid()
points(x = locmap$coord$x, y = locmap$coord$y, bg = "white")

plot(x = locmap$coord$x, 
     y = locmap$coord$y, 
     type = "n", 
     asp = 1,
     xlim = c(-10, 12),
     ylim = c(-10, 10),
     yaxt = 'n',
     xaxt = 'n',
     bty = 'n',
     xlab = "",
     ylab = "",
     main = "Corresponding ganglion cells")
plot_grid()
points(x = gcmap$x, y = gcmap$y, pch = 21, bg = "white")
@

Therefore, the visualFields package provides function to calculate where the ganglion cells that subserve a given location in the visual field are located and to calculate at which angle the axons of these ganglion cells enter the optic nerve head (optic disc), where they pass through the sclera (wall of the eye) to form the optic nerve. This function is based on Montesano et al. [@IMF:Montesano2020] which revisited the original work by Drasdo et al. [@IMF:Drasdo2007].

<<>>=

print(locmaps$p24d2$coord[23,])
print(vf2gc(locmaps$p24d2$coord[23,]))

@

The Montesano Ganglion-cell displacement function can be in conjunction with the Jansonius map describing average ganglion cell bundles paths reaching different regions of the retina [@IMF:Jan2009] [@IMF:Jan2012]. First, we can obtain the angle of incidence on the optic never head (ONH)

<<>>=

print(loc2psi(vf2gc(locmaps$p24d2$coord[23,])))

@

And from the angle of incidence, the nerve fiber bundle path can be calculated. Note that the function for calculating the trajectory will extrapolate the trajectory beyond the location of the visual field (usually to the raphe).

<<warning=FALSE, fig=TRUE>>=

# use loc2psi to calculate the incidence of the nerve fiber corresponding to a given location at the ONH
angle_of_incidence_l19 <-loc2psi(locmaps$p24d2$coord[19, ])

# use cart2jpolar for calculating the position of the visual field location in the polar coordinate system
locations <- rbind(cart2jpolar(locmaps$p24d2$coord[19, ]),
                   cart2jpolar(locmaps$p24d2$coord[23, ]),
                   cart2jpolar(locmaps$p24d2$coord[47, ]),
                   cart2jpolar(data.frame(x = 0, y = 0)))
locations$labels <- c("l19", "l23", "l47", "fixation")

# use bundePath to create a function for calculating the bundle path
path_function_l19 <- bundlePath(angle_of_incidence_l19)
path_function_l23 <- bundlePath(loc2psi(locmaps$p24d2$coord[23, ]))
path_function_l47 <- bundlePath(loc2psi(locmaps$p24d2$coord[47, ]))

bundle_path <- data.frame(y = 4:90,
                          x_l19 = path_function_l19(4:90),
                          x_l23 = path_function_l23(4:90),
                          x_l47 = path_function_l47(4:90))
ggplot(bundle_path, aes(y = y)) +
  geom_line(aes(x = x_l19)) +
  geom_point(data = locations, aes(x = -psi, y = r, color = labels, shape = labels == "fixation")) +
  geom_line(aes(x = x_l23), color = "red") +
  geom_line(aes(x = x_l47), color = "blue") +
  coord_polar(start = pi / 2, direction = -1) +
  scale_x_continuous(breaks = c(-180, -90, 0, 90, 180), limits = c(-180, 180)) +
  scale_y_continuous(limits = c(0, 60)) +
  scale_color_manual(values = c("l19" = "black", "l23" = "red", "l47" = "blue", "fixation" = "black")) +
  guides(color = "none", shape = "none")

@

In this plot, the origin corresponds to the center of the ONH, the black triangle corresponds to the fovea, and the $180^\circ$ angle corresponds to the line between the ONH center and the fovea, which is, in reality, slightly tilted downward in most patients. I DO NOT SEE THIS, BUT I MAY BE MISSING SOMETHING. ALSO THE FOVEA (TRIANGLE IF I GOT IT RIGHT?) SHOULD BE A BIT BELOW THE HORIZONTAL MERIDIAN. THE POSITION OF THE CENTER OF THE BLIND SPOT IS (15,+2) IN THE MODEL (PLUS AND NOT MINUS BECAUSE THE MODEL IS SPECIFIED FOR THE ANATOMICAL RETINA, AND IT NEEDS TO BE TURNED UPSIDE DOWN TO MATCH THE VISUAL FIELD)

[IVAN: I THOUGHT THAT PSI WAS THE ANGLE OF INCIDENCE IN THE OPTIC NERVE HEAD. THEREFORE, I CHOSE A POLAR PLOT AND NOT AN X-Y-PLOT. ALSO, I THOUGHT THAT THE 0° ANGLE OF INCIDENCE WAS DEFINED AS THE LINE BETWEEN FOVEA AND ONH. I DID NOT TURN THE POLAR COORDINATED ACCORDINGLY EVEN THOUGHT I MENTIONED THAT THE FOVEA WAS "TILTED DOWNWARD". BUT I DO NOT HAVE MUCH EXPERIENCE WITH THE MODEL, SO PLEASE CORRECT ME IF I'M WRONG. HOW WOULD I CALCULATE XY-COORDINATES?]

For convenience, visualFields also contains a function to map the angle of incidence of bundles on the ONH to the corresponding angle of the circumpapillary retinal nerve fiber layer (cpRNFL) scan. This allows to map a visual field location to its corresponding ganglion cell location, to its angle of incidence on the ONH and finally to the angle in the cpRNFL scan.

<<>>=

l23 <- locmaps$p24d2$coord[23,]

# location on the visual field to corresponding ganglion cell
gc23 <- vf2gc(l23)
print(gc23)

# ganglion cell location to angle of incidence on the ONH
psi23 <- loc2psi(gc23)
print(psi23)

# angle of incidence on the ONH to OCT cpRNFL scan angle
ang23 <- psi2oct(psi23)
print(ang23 - 360)

@

\subsection{Creating pretty reports}
Progression reports can be created as pdfs or as interactive reports with shiny. To explore them, type in the R Console the following:

<<eval = FALSE>>=

vfspa(example3, file = "test.pdf")
vfspashiny(example3)

@

\subsection{DICOM standard of visual fields}
DICOM (Digital Imaging and Communications in Medicine) standards for ophthalmic static perimetry are specified in Supplement 146 [CAN YOU PROVIDE A REFERENCE OR SPECIFY SUPPLEMENT IN WHAT?]. However, there are two functions for loading data generated in the DICOMM format created by the Humphrey Field Analyzer (HFA) by Zeiss.

Currently, the data representation in the visualFields package differs from these standards and data cannot be exported from the package to DICOMM.

\subsection{Using a different perimeter}
Different manufacturers have different conventions in perimetry. For example, clinicians working with Humphrey Field Analyzers (Carl-Zeiss-Meditec) are often used to report loss of function as negative values (e.g., MD: mean \textbf{deviation} of $-10$ dB), while those working with Octopus perimeters (Haag-Streit) often report loss as a positive value (e.g., MD: mean \textbf{defect} of 10 dB). Furthermore, clinicians working with Octopus perimeters often use different grids, even though the 24-2 and 10-2 grids are also available. Usually, fields cannot be directly compared because other setting ($L_{max}$) are also different and because different algorithms are used.

The visualField package provided normative data for the Humphrey Field Analyzer 24-2 and Goldmann size III and for Iowa's full field perimetry [@IMF:Marin2018c], which comprises two different grids, Central $26^\circ$ and Periphery (from $30^\circ$ to more than $60^\circ$), with the Goldmann Size V stimulus on the Octopus 900. The `loadoctopus` function also imports some normative data from the Octopus perimeter by Haag-Streit, but, as of now, this does not allow full use of the functionality of the visualFields package. Currently, there are no other normative references for any other perimeters or grids. Research labs can, however, use their suitable normative datasets to generate normative values for analysis with visual fields.

\subsection{Advanced topics}
\subsection{Setting up the environment}
A given visual field program has certain properties that remain unchanged during the test. In the visualFields packages these are saved in an \textbf{environment}. After setting this environment, you can only analyse data that is consistent with this environment.

The core elements of the environment that need to be setup are

-   The normative reference values (`nv`)
-   The test grid (`locmap`)
-   Graphical parameters used for the different visualization devices (`gpar`)
-   The column where the visual field measurements start in the tables (`locini`)

The `nv` environment variable also contains functions for calculating defects, probabilities and global parameters that can be accessed via the functions stated above.

visualFields provides predefined test grids `locmaps`, normative values `normvals`, and parameters for graphical display (`gpars`)

<<>>=

print(names(locmaps))
print(names(normvals))
print(names(gpars))

@

They should be consistent. For instance, `locmaps$p24d2` can only be used with one of the following `normvals`: `sunyiu_24d2_pw`, `sunyiu_24d2`, `sunyiu_24d2_pw_cps` or `sunyiu_24d2_cps`, but not with, e.g., `iowa_PC26_pw`.

Likewise, `locmaps$p24d2` and `normvals$sunyiu_24d2_pw` or `normvals$sunyiu_24d2` can only be used with `gpars$p24d2`, but not the "_csp" version `gpars$p24d2_cps`

<<getters>>=

# current normal values
print(getnv()$info)
str(getnv(), 1)

# current locmap
str(getlocmap(), 1)
# current parameters for plotting
str(getgpar(), 1)
# position of the column l1 in the dataframe
print(getlocini())

@

The default environment assumes a static white-on-white perimetry with a Humphrey perimeter, using a 24-2 grid, a SITA standard algorithm, a stimulus size of Goldman Size III. The stimulus duration and the $\Delta L_{max}$ are not explicitly stated in the info, because they are generally known and it does not impact the statistical analysis of the visual field.

Note that for switching to another perimetry program, you need to set all environment variables. visualFields has setter functions for this purpose.

<<>>=

# Set locations for Iowa Central 26 grid
setlocmap(locmaps$pPC26)
print(getlocmap()$name)
# Set normative values for Iowa Central 26 grid
setnv(normvals$iowa_PC26_pw)
print(getnv()$info$name)
# Set graphical parameters for Iowa Central 26 grid
setgpar(gpars$pPC26)

@

If the structure of the dataframe containing visual field data has changed, and the sensitivity locations start at a differen column, this can also be changed with another setter function.

<<>>=

# Set first column with sensitivity values
setlocini(24)
print(getlocini())

@

Here is the figure with the test locations of the Iowa central $26^\circ$. Notice that this map does not have any locations falling on the anatomical blind spot.

<<fig=TRUE>>=

new_locmap <- getlocmap()

plot(x = new_locmap$coord$x, 
     y = new_locmap$coord$y, 
     type = "n", 
     asp = 1,
     xlim = c(-30, 30),
     ylim = c(-34, 34),
     yaxt = 'n',
     xaxt = 'n',
     bty = 'n',
     xlab = "",
     ylab = "",
     main = "Iowa Central 26 grid of test locations")
lines(-c(30, 2.5), c(0, 0), lwd = 2, col = "lightgray")
lines(c(2.5, 30), c(0, 0), lwd = 2, col = "lightgray")
lines(c(0, 0), -c(30, 2.5), lwd = 2, col = "lightgray")
lines(c(0, 0), c(2.5, 30), lwd = 2, col = "lightgray")
lines(x = c(-2.5, 2.5), y = c(0, 0), lwd = 1.5)
lines(x = c(0, 0), y = c(-2.5, 2.5), lwd = 1.5)
for(r in c(10, 20, 30))
  draw.circle(0, 0, r, lwd = 2, col = NA, border = "lightgray")
draw.ellipse(15, -1.5, 2.75, 3.75, col = "gray", border = NA)
text(x = 0, y = -34, "horizontal eccentricity [degrees]")
text(x = -34, y = -0, "vertical eccentricity [degrees]", srt = 90)
text(x = 31, y = 0, "30\u00b0", adj = c(0, 0.5))
text(x = 0, y = 31, "30\u00b0", adj = c(0.5, 0))
points(x = new_locmap$coord$x, y = new_locmap$coord$y)

@

\subsubsection{Defaults}
The environment can be reset to its default values, the 24-2 pattern measured with the SITA algorithm on a Humphrey Field Analyzer, and with a data frame structure where the sensitivity values start at column 11.

<<>>=

setdefaults()

print(getlocini())
print(getlocmap()$name)
print(getnv()$info$name)
print(str(getnv(), 1))

@

\subsection{Customizing visualFields}
To make full use of the visualField package with other perimeters, grids, or testing algorithms (staircase, full threshold, different implementations of ZEST, etc.), it is necessary to configure visualFields to the custom test.

The first decision to make is the structure of visual field result data. In a data frame (and a loadable csv file) the first 4 columns must have the uniquely identifiable key (`id`, `eye`, `date`, `time`). To compute \textbf{deviations} from age-corrected mean normal, the age must also be included. And it is recommended to add the information about the reliability indices of the exam, such as false positive rate (`fpr`), false negative rate (`fnr`), and fixation losses (`fl`), although the last two have recently been found not to be "reliable". To design your structure, looking at the datasets included in the visualFields package may be useful.

The first 10 columns of `vfpwgRetest24d2` contains the key, age, and other information.

<<>>=
str(vfpwgRetest24d2[,1:10])
@

After the information regarding the test, etc, must come the columns representing the visual field locations, each row containing the sensitivities for a specific exam of the eye of a patient.

<<>>=
str(vfpwgRetest24d2[,11:21])
@

The name of the columns with sensitivity values of an exam must be prefixed by "l" and followed by the corresponding conecutive location number. So for a patient using the 24-2 grid, the full record is:

<<>>=
print(vfpwgRetest24d2[1,])
@

Depending on the structure the visualField environment variable `locini` must be adjusted so that its value is the column number of the first sensitivity value, `l1`. This may be done with the setter `setlocini()`.

For a custom grid of location, it is possible to create and set the location map and its graphical parameters. visualFields has a function `vfgpar()` to generate graphical parameters for a given grid. Here is an example with the Octopus "G1" map, that uses `vfread` to read visualField's ready visual field data.

[I WANTED TO SHOW SOME OF THE FUNCTIONALITY OF THE LOADOCTOPUS FUNCTION, BUT I COULD DOCUMENT THIS ELSEWHERE]

[THE PROBLEM HERE IS THAT NOW PEOPLE WORKING WITH THE OCTOPUS HAVE TO FIND THE COORDINATES ELSEWHERE, AGAIN, BECAUSE THEY DO NOT HAVE ACCESS TO g1.csv. COULD IT BE PROVIDED IN THE PACKAGE?]

<<eval=FALSE>>=
# read the Octopus G1 coordinates and create the locmap
g1 <- list(coord = read.csv("./g1.csv"), name = "G1", desc = "The G1 location map used by Octopus perimeters", bs = numeric())
str(g1)
# set the G1 locmap
setlocmap(g1)
# create and set the graphical parameters
setgpar(vfgpar(g1$coord))
# read visual fields and plot the sensitivities
vfplot(vfread("./vfg1.csv"), type = "s")
@

The function `vfgpar()` that generates the graphical parameters has many input argument to provide as much flexibility as possible regarding the color schemes to use for probability scales, grayscale, etc.

We cannot compute or visualize total deviations, pattern deviations, or their corresponding probability maps, because we do not have normative reference values for this particular test. If we had a visualField's ready csv file with a suitable normative dataset, we could read it with `vfread()`, use the previously used function `nvgenerate()`, and set the generated normative values with `setnv()`.

Finally, if we want to go to the default settings, we ran again:

<<>>=
setdefaults()
@

%% -- Summary and discussion ---------------------------------------------------

\section{Summary and discussion} \label{sec:summary}

The \pkg{visualFields} package provides a comprehensive set of tools for analyzing visual field data. It is part of the Open Perimetry Initiative and supports a wide range of analyses, from basic visualizations to advanced statistical modeling. Future work could include extending the package to support additional perimeters and integrating new methods for visual field analysis.

%% -- Acknowledgements ---------------------------------------------------

\section{Acknowledgments}
The visualField's package would not have existed if it wasn't for the important contribution of many contributors who partially funded the development of the package, and/or contributed datasets, code, and above all insight on visual fields analysis and about perimetry and visual sciences at large. Huge thanks to:
  - William H Swanson
  - Michael Wall
  - Andrew Turpin
  - Paul H Artes
  - Giovanni Montesano
  - Mitchell W Dul

%% -- Bibliography -------------------------------------------------------------

\bibliography{references}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
